# ğŸ§  Multimodal RAG System

> **Table No. 18 | Team: ManageSphere**
>
> **Evidence-Based Multimodal Retrieval-Augmented Generation**
> 
> A production-ready system for ingesting, retrieving, and reasoning across text, images, and audio with explicit uncertainty handling and conflict detection.

## ğŸ¯ Features

### Core Capabilities
- âœ… **Multimodal Data Ingestion**: PDF, DOCX, TXT, Images (JPG, PNG), Audio (MP3, WAV)
- âœ… **Unified Cross-Modal Retrieval**: Semantic search across all modalities
- âœ… **Evidence-Grounded Generation**: All responses cite sources
- âœ… **Conflict Detection**: Identifies and presents contradictory information
- âœ… **Uncertainty Awareness**: Explicitly acknowledges gaps and low confidence
- âœ… **Adaptive Retrieval**: Dynamically adjusts search strategy
- âœ… **Hallucination Suppression**: Refuses to answer without evidence
- âœ… **ğŸŒ Auto-Translate Knowledge Base**: Ask in 30+ languages, get answers in your language

### System Design
- **No heavy resources**: Uses lightweight models (Llama 3.2 3B, CLIP ViT-B/32, Whisper Tiny)
- **No blind vector search**: Every retrieval decision is logged and justified
- **Explainable pipeline**: Transparent confidence scoring and conflict detection
- **Failure-tolerant**: Graceful degradation when components unavailable

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- 8GB RAM minimum
- ~5GB disk space for models
- (Optional) Ollama installed for local LLM

### Installation

1. **Clone the repository**
```bash
cd multimodal_rag
```

2. **Create virtual environment**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Mac/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
# Copy .env.example to .env
cp .env.example .env

# Edit .env to configure:
# - OLLAMA_BASE_URL (if using Ollama)
# - OPENROUTER_API_KEY (if using fallback API)
```

5. **Install Ollama (recommended for local LLM)**
```bash
# Windows: Download from https://ollama.ai
# Then pull the model:
ollama pull llama3.2:3b
```

### Running the System

```bash
# Start the server
cd backend
python app.py

# Or using uvicorn directly
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

Open http://localhost:8000 in your browser.

## ğŸ“– Usage

### 1. Upload Documents

Drag and drop or click to upload:
- **Text**: PDF, DOCX, TXT files
- **Images**: JPG, PNG, diagrams, charts
- **Audio**: MP3, WAV recordings

The system will:
- Extract content and metadata
- Generate embeddings
- Store in vector database
- Display chunk count

### 2. Query the Knowledge Base

Ask questions naturally:
- "What are the main findings about X?"
- "Show me diagrams related to Y"
- "What was said about Z in the audio?"
- "Compare the perspectives on W"

**Or ask in your language** ğŸŒ:
- ğŸ‡®ğŸ‡³ "à¤¯à¤¹ à¤®à¤¶à¥€à¤¨ à¤•à¥ˆà¤¸à¥‡ à¤•à¤¾à¤® à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ?" (Hindi)
- ğŸ‡ªğŸ‡¸ "Â¿CÃ³mo funciona esto?" (Spanish)
- ğŸ‡«ğŸ‡· "Comment Ã§a marche?" (French)
- ğŸ‡¯ğŸ‡µ "ã“ã‚Œã¯ã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã¾ã™ã‹ï¼Ÿ" (Japanese)

The system automatically detects your language and responds accordingly! See [AUTO_TRANSLATE_FEATURE.md](AUTO_TRANSLATE_FEATURE.md) for details.

### 3. Interpret Responses

**High Confidence** (Green Badge):
- Strong evidence from multiple sources
- Cross-modal agreement
- Full citations provided

**Medium Confidence** (Yellow Badge):
- Limited sources or single modality
- Explicit caveats about uncertainty
- Distinguishes facts from inferences

**Low Confidence / Refusal** (Red Badge):
- Insufficient evidence
- Lists missing information
- Suggests next steps

**Conflicts Detected** (Orange Warning):
- Contradictory sources identified
- Multiple perspectives presented
- User decides which to trust

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interface                         â”‚
â”‚                    (HTML + CSS + JavaScript)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                  â”‚
             â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload Endpoint   â”‚           â”‚    Query Endpoint       â”‚
â”‚   /upload (POST)    â”‚           â”‚    /query (POST)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                  â”‚
           â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingestion Pipeline â”‚           â”‚   RAG Generator         â”‚
â”‚  - Text Processor   â”‚      â”Œâ”€â”€â”€â”€â”¤  - Query Analyzer       â”‚
â”‚  - Image Processor  â”‚      â”‚    â”‚  - Cross-Modal Retrieverâ”‚
â”‚  - Audio Processor  â”‚      â”‚    â”‚  - Confidence Scorer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚  - Conflict Detector    â”‚
           â”‚                 â”‚    â”‚  - LLM Client           â”‚
           â–¼                 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚              â”‚
â”‚ Embedding Manager   â”‚      â”‚              â”‚
â”‚  - Text Embedder    â”‚      â”‚              â”‚
â”‚  - Image Embedder   â”‚      â”‚              â”‚
â”‚  (Cross-Modal Align)â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â–¼              â–¼
           â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    Vector Store         â”‚
                       â”‚    (ChromaDB)           â”‚
                       â”‚  - HNSW Index           â”‚
                       â”‚  - Metadata Filtering   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¬ Technical Details

### Embedding Strategy
- **Text**: `sentence-transformers/all-MiniLM-L6-v2` (384-dim)
- **Images**: CLIP ViT-B/32 â†’ PCA projection to 384-dim
- **Audio**: Whisper Tiny transcription â†’ Text embedding
- **Cross-Modal**: Unified 384-dim space for semantic alignment

### Retrieval Pipeline
1. **Query Analysis**: Detect required modalities and complexity
2. **Multi-Modal Retrieval**: Search each modality independently
3. **Cross-Modal Scoring**: Boost results with multi-modal support
4. **Re-Ranking**: Combine relevance Ã— confidence, remove duplicates

### Confidence Scoring
```
Confidence = (0.5 Ã— avg_relevance) + (0.5 Ã— avg_source_quality)
           + cross_modal_bonus + diversity_bonus

High:   â‰¥ 0.8
Medium: 0.6 - 0.8
Low:    < 0.6 (triggers refusal or caveats)
```

### Conflict Detection
1. Extract factual claims from each source
2. Compute pairwise semantic similarity
3. Detect contradictions via negation patterns or numerical differences
4. Present all perspectives without collapsing

## ğŸ“Š Evaluation Criteria Met

| Requirement | Implementation | Status |
|------------|----------------|--------|
| Multimodal ingestion | PDF, DOCX, TXT, JPG, PNG, MP3, WAV | âœ… |
| Unified storage | Single ChromaDB collection with modality tags | âœ… |
| Cross-modal retrieval | CLIP-based shared embedding space | âœ… |
| Intent-aware strategy | Query analyzer with logged reasoning | âœ… |
| Evidence-based generation | All responses cite [Source X] | âœ… |
| Uncertainty awareness | Confidence scoring + refusal logic | âœ… |
| Conflict detection | Claim extraction + semantic comparison | âœ… |
| Adaptive retrieval | Iterative refinement logged | âœ… |
| Hallucination suppression | Refuses when confidence < threshold | âœ… |
| Failure tolerance | Graceful degradation, error handling | âœ… |

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/ -v

# Test ingestion
pytest tests/test_ingestion.py -v

# Test retrieval
pytest tests/test_retrieval.py -v

# Test generation
pytest tests/test_generation.py -v
```

## ğŸ“ Project Structure

```
multimodal_rag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ models/                # Data models
â”‚   â”œâ”€â”€ ingestion/             # File processors
â”‚   â”œâ”€â”€ embeddings/            # Embedding generators
â”‚   â”œâ”€â”€ storage/               # Vector database
â”‚   â”œâ”€â”€ retrieval/             # Search logic
â”‚   â”œâ”€â”€ generation/            # RAG pipeline
â”‚   â””â”€â”€ utils/                 # Logging, metrics
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ js/
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/               # Uploaded files
â”‚   â”œâ”€â”€ processed/             # Processed data
â”‚   â””â”€â”€ chroma_db/             # Vector database
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .env.example               # Environment template
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `.env` to customize:

```bash
# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OPENROUTER_API_KEY=your_key_here  # Fallback

# Retrieval
DEFAULT_TOP_K=10
CONFIDENCE_THRESHOLD=0.6
MAX_RETRIEVAL_ITERATIONS=3

# Upload Limits
MAX_FILE_SIZE_MB=50
```

## ğŸ“ Example Queries

### Simple Text Query
```
Q: "What is photosynthesis?"
A: [High Confidence] Photosynthesis is the process by which plants convert light 
   energy to chemical energy [Source 1]. It occurs in chloroplasts [Source 2].
```

### Cross-Modal Query
```
Q: "Show me diagrams of the water cycle"
A: [Medium Confidence] Retrieved 3 images showing evaporation, condensation, and 
   precipitation [Source 1 - image], with supporting text descriptions [Source 2, 3].
```

### Conflict Query
```
Q: "What is the optimal temperature for enzyme activity?"
A: [Conflict Detected] Source 1 indicates 37Â°C for human enzymes, while Source 2 
   states thermophilic enzymes work at 70-90Â°C. Both are correct for different contexts.
```

### Refusal Example
```
Q: "What is the stock price of company X?"
A: [Unable to Answer] No evidence found. Please upload financial documents or 
   market data to enable this query.
```

## ğŸ¤ Contributing

**Team ManageSphere | Table No. 18**

Built for the **Multimodal RAG System Hackathon**.

GitHub: [rahulranjan9770](https://github.com/rahulranjan9770)

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- **Sentence Transformers**: Text embeddings
- **OpenAI CLIP**: Image-text alignment
- **Whisper**: Audio transcription
- **ChromaDB**: Vector database
- **Ollama**: Local LLM inference

---

**Built with â¤ï¸ for responsible, evidence-based AI**
